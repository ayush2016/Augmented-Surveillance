Augmented WarZone

Problem breakdown:-
a. Get position data of person(s) using distance/ location sensors.
b. Get id information of person(s) using RFID sensors.
c. Estimate position information of person(s) using camera footage.
d. Merge data
e. Present the data on suitable display system.

Phase I
a. Using smart phones, get GPS location data of 2 or more people in a designated area.
b. Create an app that will broadcast the GPS and identity of individuals (eg Name/ Phone name/ Google id/ etc) from their mobiles.
c. Receive the data on another mobile/ receiver.
d. Get image sequence of same area using camera.
e. Calibrate the camera to get Geo-positions of various pre-earmarked locations in the field of view.
f. Display location of users along with ID on Map app using mobile data.
g. Display id of users on Video display along with the actual scene sequence - need to detect humans in the video feed, get their geo-locations from image and then merge id data.
h. Display id and location data on Google glasses - challenge of getting location info of people using the camera on the glass.
i. Using Bounding box, mark the users as green (id available) or red (id not available).

Phase II
a. Instead of phones, use RFID sensors and location sensors - step-wise migration from smart phone to sensors.
b. Network sensors - IoT.
c. Sensor fusion with video info.
d. Display on monitor, mobile app and Google glasses.
e. Mark users as known / unknown.

Phase III
a. Sensor fusion in a dynamic scenario.
b. Display on monitor, mobile app and Google glasses.
c. Mark users as known / unknown.
